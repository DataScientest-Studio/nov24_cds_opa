# Page Mod√©lisation 
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import shap
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import os
import warnings

warnings.filterwarnings('ignore')


st.set_page_config(page_title="Mod√©lisation du Risque", layout="wide")

# --- D√©finition des param√®tres du meilleur mod√®le ---
OPTIMAL_PARAMS = {
    'n_estimators': 134,
    'max_depth': 10,
    'min_samples_leaf': 1,
    'max_features': 'log2',
    'criterion': 'entropy',
}

# --- Initialisation de st.session_state pour les hyperparam√®tres ---
# Cela garantit que les valeurs des sliders persistent et peuvent √™tre r√©initialis√©es.
if 'hyperparams' not in st.session_state:
    st.session_state.hyperparams = OPTIMAL_PARAMS.copy()

if 'reset_counter' not in st.session_state:
    st.session_state.reset_counter = 0

# --- Fonction callback pour le bouton reset ---
def reset_to_optimal():
    """R√©initialise les hyperparam√®tres dans session_state aux valeurs optimales."""
    st.session_state.hyperparams = OPTIMAL_PARAMS.copy()

# --- Section header ---
st.title("üß† Mod√©lisation Interactive : De la Pr√©diction au Filtrage de Risque")
st.markdown("""
Cette page interactive vous emm√®ne au c≈ìur de la partie Mod√©lisation du projet. L'objectif initial : pr√©dire si une action du NASDAQ 100 allait **surperformer le march√© (Classe 1)** ou **sous-performer (Classe 0)** en se basant uniquement sur ses donn√©es financi√®res fondamentales.

Cependant, nos recherches ont r√©v√©l√© une v√©rit√© nuanc√©e mais n√©anmoins int√©ressante : s'il est difficile de pr√©dire les "gagnants" avec une certitude absolue, notre mod√®le s'est av√©r√© **fiable pour identifier les "perdants" potentiels**.

Nous avons donc r√©orient√© notre strat√©gie. Cet outil n'est pas un preneur de d√©cision, mais un **syst√®me de gestion des risques**. Il vous permet de :
- **Explorer** comment les hyperparam√®tres d'un `RandomForestClassifier` influencent sa capacit√© √† d√©tecter les risques.
- **Comprendre** quelles caract√©ristiques financi√®res (croissance, rentabilit√©, endettement) sont les plus d√©terminantes.
- **D√©couvrir** comment, en se concentrant sur les pr√©dictions √† haute confiance, le mod√®le devient un filtre de risque tr√®s pr√©cis.
""")
st.info("Ajustez les param√®tres, entra√Ænez le mod√®le, ou cliquez sur 'R√©initialiser' pour revenir √† notre configuration la plus performante.")

# --- Loading de la donn√©e ---
DATA_PATH = 'notebooks/csv/N100_fundamentals_v3.csv'

@st.cache_data
def load_and_prep_data(path):
    # (Le reste de la fonction est inchang√©)
    if not os.path.exists(path) and os.path.exists(os.path.join(os.path.dirname(__file__), '..', path)):
        path = os.path.join(os.path.dirname(__file__), '..', path)
    if not os.path.exists(path):
        st.error(f"Erreur: Le fichier de donn√©es est introuvable : `{path}`")
        return None, None, None, None
    df = pd.read_csv(path)
    df = df.sort_values(by='date')
    df['index'] = df.symbol + '_' + df.calendarYear.astype('string')
    df = df.set_index('index')
    df_final = df.dropna()
    if 'netIncomePerShare' in df_final.columns and 'shareValue' in df_final.columns:
        df_final['earningsYield'] = df_final['netIncomePerShare'] / df_final['shareValue']
    columns_to_drop = [
        'return', 'date_NY', 'date', 'benchmark', 'symbol', 'calendarYear', 'shareValue', 'peRatio_YoY_Growth',
        'peRatio', 'shareValue_YoY_Growth', 'marketCap_YoY_Growth', 'roe_YoY_Growth', 'roic_YoY_Growth',
        'netIncomePerShare_YoY_Growth', 'debtToEquity_YoY_Growth', 'netIncomePerShare', 'marginProfit_YoY_Growth'
    ]
    df_final = df_final.drop(columns=[col for col in columns_to_drop if col in df_final.columns], errors='ignore')
    if 'target' not in df_final.columns:
        st.error("Erreur: La colonne 'target' est manquante.")
        return None, None, None, None
    condition = df_final.index.str.contains('2023')
    X_test = df_final[condition]
    X_train = df_final[~condition]
    y_test = X_test.target
    y_train = X_train.target
    X_train = X_train.drop('target', axis=1)
    X_test = X_test.drop('target', axis=1)
    return X_train, y_train, X_test, y_test

# --- Fonctions helper ---
def create_plotly_confusion_matrix(cm, title, colorscale):
    labels = ['Classe 0 (Sous-perf.)', 'Classe 1 (Sur-perf.)']
    fig = px.imshow(cm, labels=dict(x="Pr√©diction", y="Vraie Valeur", color="Nombre"), x=labels, y=labels,
                    text_auto=True, color_continuous_scale=colorscale, title=title)
    fig.update_layout(xaxis_title="Classe Pr√©dite", yaxis_title="Classe R√©elle", yaxis={'autorange': 'reversed'})
    return fig

@st.cache_data
def train_and_evaluate(_X_train, _y_train, _X_test, params):
    model = RandomForestClassifier(random_state=42, **params)
    model.fit(_X_train, _y_train)
    return model, model.predict(_X_test), model.predict_proba(_X_test)

def get_shap_explanation(_model, _data_to_explain):
    explainer = shap.TreeExplainer(_model)
    return explainer(_data_to_explain)

# --- Logique principale de la page ---
X_train, y_train, X_test, y_test = load_and_prep_data(DATA_PATH)
if X_train is None:
    st.stop()

# Section pour les hyperparam√®tres
st.header("‚öôÔ∏è Configuration des Hyperparam√®tres")
st.info("Ajustez les hyperparam√®tres pour voir leur impact sur la performance. Un mod√®le plus complexe est-il toujours meilleur ?")

# Le bouton de r√©initialisation avec compteur
if st.button("üîÑ R√©initialiser aux Param√®tres Optimaux"):
    st.session_state.hyperparams = OPTIMAL_PARAMS.copy()
    st.session_state.reset_counter += 1  # Incr√©mente le compteur pour forcer la recr√©ation des widgets
    st.rerun()

with st.form("hyperparameter_form"):
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Structure de la For√™t")
        # Utilisation du reset_counter dans les keys pour forcer la recr√©ation
        n_estimators = st.slider(
            'Nombre d\'arbres (n_estimators)', 
            10, 500, 
            value=st.session_state.hyperparams['n_estimators'],
            key=f'slider_n_estimators_{st.session_state.reset_counter}',
            help="Plus d'arbres r√©duit le surapprentissage, mais augmente le temps de calcul."
        )
        max_depth = st.slider(
            'Profondeur maximale (max_depth)', 
            3, 30, 
            value=st.session_state.hyperparams['max_depth'],
            key=f'slider_max_depth_{st.session_state.reset_counter}',
            help="Contr√¥le la complexit√© de chaque arbre. Une profondeur trop √©lev√©e peut mener au surapprentissage."
        )
    with col2:
        st.subheader("Conditions de Division")
        min_samples_leaf = st.slider(
            '√âchantillons min. par feuille', 
            1, 20, 
            value=st.session_state.hyperparams['min_samples_leaf'],
            key=f'slider_min_samples_leaf_{st.session_state.reset_counter}',
            help="Exige un nombre minimum d'√©chantillons dans une feuille, lissant ainsi le mod√®le."
        )
        max_features = st.select_slider(
            'Caract√©ristiques max.', 
            ['sqrt', 'log2', None], 
            value=st.session_state.hyperparams['max_features'],
            key=f'slider_max_features_{st.session_state.reset_counter}',
            help="Nombre de caract√©ristiques √† consid√©rer pour chaque division."
        )
        
        criterion_options = ['gini', 'entropy']
        criterion = st.selectbox(
            'Crit√®re de division', 
            criterion_options, 
            index=criterion_options.index(st.session_state.hyperparams['criterion']),
            key=f'slider_criterion_{st.session_state.reset_counter}'
        )

    submitted = st.form_submit_button("üöÄ Entra√Æner le Mod√®le")

# Mise √† jour du session_state quand le formulaire est soumis
if submitted:
    # Mise √† jour des hyperparam√®tres dans le session_state
    st.session_state.hyperparams = {
        'n_estimators': n_estimators,
        'max_depth': max_depth,
        'min_samples_leaf': min_samples_leaf,
        'max_features': max_features,
        'criterion': criterion,
    }
    
    # Entra√Ænement du mod√®le
    with st.spinner("Entra√Ænement du mod√®le en cours..."):
        st.session_state.model, st.session_state.predictions, st.session_state.probabilities = train_and_evaluate(
            X_train, y_train, X_test, st.session_state.hyperparams
        )
    st.session_state.model_trained = True

st.divider()

if 'model_trained' not in st.session_state:
    st.info("Veuillez cliquer sur 'Entra√Æner le Mod√®le' pour commencer l'analyse.")
    st.stop()

# --- Performance Globale ---
st.header("üìä R√©sultats Globaux sur l'Ensemble de Test (Ann√©e 2023)")
st.info("Analysez la performance globale. Observez la diff√©rence de pr√©cision et de rappel entre la **Classe 0 (Sous-performance)** et la **Classe 1 (Surperformance)**. Le mod√®le est-il plus dou√© pour l'une que pour l'autre ?")
with st.container(border=True):
  res_col1, res_col2 = st.columns([1, 1])
  with res_col1:
      st.subheader("Rapport de Classification")
      accuracy = accuracy_score(y_test, st.session_state.predictions)
      st.metric("Pr√©cision (Accuracy)", f"{accuracy:.2%}")
      st.code(classification_report(y_test, st.session_state.predictions, target_names=['Classe 0 (Sous-perf.)', 'Classe 1 (Sur-perf.)']))
  with res_col2:
      st.subheader("Matrice de Confusion G√©n√©rale")
      cm = confusion_matrix(y_test, st.session_state.predictions, labels=[0, 1])
      fig_cm = create_plotly_confusion_matrix(cm, "Matrice de Confusion G√©n√©rale", "Blues")
      st.plotly_chart(fig_cm, use_container_width=True)

st.divider()

st.header("üëë Importance des Caract√©ristiques : L'ADN d'une D√©cision")
st.info("Quels sont les indicateurs financiers les plus influents ? Le mod√®le a appris √† raisonner comme un analyste, en se concentrant sur la croissance (`revenuePerShare_YoY_Growth`), la rentabilit√© (`roic`) et la structure financi√®re (`debtToEquity`).")
with st.container(border=True):
  feature_importances = pd.Series(st.session_state.model.feature_importances_, index=X_train.columns).sort_values(ascending=False)
  fig_imp = px.bar(feature_importances.head(15), orientation='h', title="Top 15 des Caract√©ristiques les plus Importantes", labels={'value': 'Importance (Gini)', 'index': 'Caract√©ristique'})
  fig_imp.update_layout(yaxis={'categoryorder':'total ascending'})
  st.plotly_chart(fig_imp, use_container_width=True)

st.divider()

# --- Analyse Haute-Confiance ---

st.header("üéØ Le C≈ìur de la Strat√©gie : Le Filtrage par la Confiance")
st.info("""
C'est ici que la valeur du mod√®le se r√©v√®le. Au lieu de consid√©rer toutes les pr√©dictions, nous ne gardons que celles o√π le mod√®le est le plus **s√ªr de lui**.
En augmentant le seuil de confiance, nous passons d'un mod√®le de pr√©diction g√©n√©rale √† un **filtre de risque de haute pr√©cision**. Observez comment la pr√©cision sur les pr√©dictions restantes (notamment pour la **Classe 0**) augmente drastiquement.
""")
with st.container(border=True):
    confidence_threshold = st.slider("Seuil de confiance pour l'analyse", 0.5, 1.0, 0.7, 0.01, help="Filtre pour n'analyser que les pr√©dictions o√π la probabilit√© pr√©dite est sup√©rieure √† ce seuil.")

    df_results = X_test.copy()
    df_results['true_label'] = y_test
    df_results['prediction'] = st.session_state.predictions
    df_results['confidence'] = np.max(st.session_state.probabilities, axis=1)
    df_results['is_correct'] = (df_results['prediction'] == df_results['true_label']).astype(int)
    high_confidence_df = df_results[df_results['confidence'] > confidence_threshold]
    hc_col1, hc_col2, hc_col3 = st.columns(3)
    total_hc, correct_hc = len(high_confidence_df), high_confidence_df['is_correct'].sum()
    hc_col1.metric("Pr√©dictions √† Haute Confiance", f"{total_hc}")
    hc_col2.metric("Correctes", f"{correct_hc} ({correct_hc/total_hc:.1%})" if total_hc > 0 else "0")
    hc_col3.metric("Incorrectes", f"{total_hc - correct_hc} ({(total_hc - correct_hc)/total_hc:.1%})" if total_hc > 0 else "0")

st.divider()

if 'high_confidence_df' in locals() and not high_confidence_df.empty:
    st.subheader(f"Matrice de Confusion (Confiance > {confidence_threshold:.0%})")
    st.info("Notez la forte r√©duction des erreurs, en particulier des Faux Positifs (pr√©dire une sous-performance qui n'a pas lieu).")
    with st.container(border=True):
        cm_hc = confusion_matrix(high_confidence_df['true_label'], high_confidence_df['prediction'], labels=[0, 1])
        st.plotly_chart(create_plotly_confusion_matrix(cm_hc, f'Matrice de Confusion (Confiance > {confidence_threshold:.0%})', "Greens"), use_container_width=True)
st.divider()

# --- Analyse SHAP ---
st.header("üïµÔ∏è Analyse SHAP : Comprendre l'Arch√©type de l'Entreprise √† Risque")
st.markdown("""
M√™me un bon mod√®le fait des erreurs. L'analyse SHAP nous permet de les diss√©quer pour comprendre **pourquoi** le mod√®le s'est tromp√© sur les cas les plus difficiles (les erreurs √† haute confiance). 
Cela nous aide √† d√©finir l'**arch√©type de l'entreprise √† risque** que le mod√®le a appris √† identifier : une combinaison de croissance stagnante, de faible rentabilit√© et d'une structure financi√®re fragile.
""")

high_confidence_incorrect_df = high_confidence_df[high_confidence_df['is_correct'] == 0] if 'high_confidence_df' in locals() else pd.DataFrame()

if not high_confidence_incorrect_df.empty:
    st.warning(f"**{len(high_confidence_incorrect_df)}** erreur(s) trouv√©e(s) avec une confiance > {confidence_threshold:.0%}. Analyse en cours...")
    X_to_explain = X_test.loc[high_confidence_incorrect_df.index]
    
    # Cr√©ation d'une cl√© de cache unique pour les valeurs SHAP
    error_indices_sorted = sorted(high_confidence_incorrect_df.index.astype(str))
    cache_key = f"shap_{confidence_threshold}_{hash(tuple(error_indices_sorted))}"
    
    # Check si les valeurs SHAP sont d√©j√† en cache
    if (not hasattr(st.session_state, 'current_shap_key') or 
        st.session_state.current_shap_key != cache_key):
        
        with st.spinner("Calcul des valeurs SHAP pour les erreurs..."):
            st.session_state.current_shap_explanation = get_shap_explanation(st.session_state.model, X_to_explain)
            st.session_state.current_shap_key = cache_key
            st.session_state.current_x_indices = list(X_to_explain.index)
    
    shap_explanation = st.session_state.current_shap_explanation
    
    # V√©rifie si les indices de X_to_explain correspondent √† ceux d√©j√† en cache
    if (hasattr(st.session_state, 'current_x_indices') and 
        st.session_state.current_x_indices != list(X_to_explain.index)):
        # Force le recalcul des valeurs SHAP si les indices ne correspondent pas
        with st.spinner("Recalcul des valeurs SHAP..."):
            st.session_state.current_shap_explanation = get_shap_explanation(st.session_state.model, X_to_explain)
            st.session_state.current_shap_key = cache_key
            st.session_state.current_x_indices = list(X_to_explain.index)
        shap_explanation = st.session_state.current_shap_explanation
    
    st.subheader("R√©sum√© SHAP des Erreurs")
    st.info("Ce graphique montre les caract√©ristiques qui ont le plus contribu√© aux **erreurs** du mod√®le sur le sous-ensemble filtr√©. Quelles sont les caract√©ristiques qui 'trompent' le plus notre mod√®le ?")
    fig_summary, ax_summary = plt.subplots()
    shap.summary_plot(shap_explanation[:,:,1], show=False, plot_type="dot")
    st.pyplot(fig_summary)
    plt.clf()

    st.subheader("Analyse D√©taill√©e d'une Erreur Sp√©cifique")
    st.info("Diss√©quons une erreur. Le graphique 'force plot' montre les forces (en rouge) qui ont pouss√© la pr√©diction vers la classe incorrecte, et les forces (en bleu) qui poussaient dans la bonne direction.")
    error_choice = st.selectbox(
        "Choisissez une erreur √† inspecter en d√©tail :",
        options=X_to_explain.index,
        format_func=lambda idx: f"{idx} (Pr√©dit: {int(high_confidence_incorrect_df.loc[idx, 'prediction'])}, R√©el: {int(high_confidence_incorrect_df.loc[idx, 'true_label'])})",
        key=f"error_select_{cache_key}"
    )
    if error_choice:
        instance_info = high_confidence_incorrect_df.loc[error_choice]
        st.write(f"**Vraie Classe :** `{int(instance_info['true_label'])}` | **Classe Pr√©dite :** `{int(instance_info['prediction'])}` | **Confiance :** `{instance_info['confidence']:.2%}`")
        
        try:
            error_position = list(X_to_explain.index).index(error_choice)
            
            if error_position >= shap_explanation.shape[0]:
                st.error(f"Erreur critique: D√©calage entre les donn√©es. Recalcul forc√©...")
                with st.spinner("Recalcul complet des valeurs SHAP..."):
                    st.session_state.current_shap_explanation = get_shap_explanation(st.session_state.model, X_to_explain)
                    st.session_state.current_shap_key = cache_key
                    st.session_state.current_x_indices = list(X_to_explain.index)
                shap_explanation = st.session_state.current_shap_explanation
                
                if error_position < shap_explanation.shape[0]:
                    single_instance_explanation = shap_explanation[error_position, :, 1]
                    plt.figure(figsize=(10, 3))
                    shap.force_plot(single_instance_explanation, matplotlib=True, show=False, text_rotation=15)
                    plt.tight_layout()
                    st.pyplot(plt.gcf())
                    plt.clf()
                else:
                    st.error("Impossible de r√©soudre le probl√®me de d√©calage des donn√©es.")
            else:
                single_instance_explanation = shap_explanation[error_position, :, 1]
                
                plt.figure(figsize=(10, 3))
                shap.force_plot(single_instance_explanation, matplotlib=True, show=False, text_rotation=15)
                plt.tight_layout()
                st.pyplot(plt.gcf())
                plt.clf()
                
        except (ValueError, IndexError) as e:
            st.error(f"Erreur lors de l'analyse SHAP pour cette instance: {e}")
else:
    st.success(f"‚úÖ Excellent ! Aucune erreur avec une confiance > {confidence_threshold:.0%} n'a √©t√© trouv√©e avec la configuration actuelle.")